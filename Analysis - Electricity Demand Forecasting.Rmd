---
title: "HW4"
author: "Dhairya Jayesh Chheda"
date: "2024-02-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# install.packages("polyreg")
```

```{r}
# library(stats)
library(polyreg)
```

```{r}
data = readxl::read_excel("/Users/dhairya/Documents/Time Series Analysis/Project/dataset.xlsx")
```

```{r}
head(data, 5)
```

# HW 3

## Question 3

```{r}
# time series of variable 1 - demand
cat("Daily Electricity Demand in 2015")
plot(data$demand, type="l", main="Demand", xlab="Day of Year", ylab = "Demand (GW)")
```

```{r}
# time series of variable 2 - temperature
cat("Daily Temperature in 2015")
plot(data$max_temperature, type="l", main="Temperature", xlab="Day of Year", ylab = "Temperature (C)")
```

```{r}
# normalizing for numerical stability
N = 365
time = 1:N
time_normalized = (time - mean(time)) / sd(time)
```

```{r}
# checking the AIC score for demand
aic_demand = c()
for (degree in c(1:10)) {
  aic_demand[degree] = AIC(lm(data$demand~poly(time_normalized, degree)))
}

plot(aic_demand, type='l', main='AIC vs Degree of polynomial', xlab='Degree')
```
##### From the AIC plot for demand, we can infer that polynomial of degree 6 works best since it has the lowest AIC score comparatively.

```{r}
# checking the AIC score for temperature
aic_temp = c()
for (degree in c(1:10)) {
  aic_temp[degree] = AIC(lm(data$max_temperature~poly(time_normalized, degree)))
}

plot(aic_temp, type='l', main='AIC vs Degree of polynomial', xlab='Degree')
```
##### From the AIC plot for temperature, we can infer that polynomial of degree 4 works best since it has the lowest AIC score comparatively.

```{r}
# fitting a polynomial of degree 6 for demand
res_demand = lm(data$demand~poly(time_normalized, 6))
summary(res_demand)

# plotting the residuals for demand
demand_residual = residuals(res_demand)
plot(demand_residual, main='Residuals for Demand')
```

```{r}
# fitting a polynomial of degree 4 for temperature
res_temperature = lm(data$max_temperature~poly(time_normalized, 4))
summary(res_temperature)

# plotting the residuals for temperature
temperature_residual = residuals(res_temperature)
plot(temperature_residual, main='Residuals for Temperature')
```

## Question 4

### Method 1

```{r}
# computing the moving average with window size = 10 for residual
demand_residual_filtered = filter(demand_residual^2, rep(1/10, 10), sides=2)
plot(demand_residual_filtered, main='Variance of Demand')
```
##### It is evident from the above plot that the variance for demand does not look stationary. The plot shows fluctuations over time, indicating variability in the data.

```{r}
# computing the moving average with window size = 10 for temperature
temperature_residual_filtered = filter(temperature_residual^2, rep(1/10, 10), sides=2)
plot(temperature_residual_filtered, main='Variance of Temperature')
```
##### It is evident from the above plot that the variance for temperature does not look stationary. The plot shows fluctuations over time, indicating variability in the data.

### Method 2

```{r}
# trying to difference the series and check for stationarity again
demand = data$demand - mean(data$demand)
temperature = data$max_temperature - mean(data$max_temperature)
```

```{r}
# re-doing the same process and checking the variance for demand
res_demand = lm(demand~poly(time_normalized, 6))
summary(res_demand)
demand_residual = residuals(res_demand)
plot(demand_residual, main='Residuals for Demand')

demand_residual_filtered = filter(demand_residual^2, rep(1/10, 10), sides=2)
plot(demand_residual_filtered, main='Variance of Demand')
```
##### Even after differencing the series, it is evident from the above plot that the variance for demand does not look stationary.

```{r}
# re-doing the same process and checking the variance for temperature
res_temperature = lm(temperature~poly(time_normalized, 4)) # try using cycle
summary(res_temperature)
temperature_residual = residuals(res_temperature)
plot(temperature_residual, main='Residuals for Temperature')

temperature_residual_filtered = filter(temperature_residual^2, rep(1/10, 10), sides=2)
plot(temperature_residual_filtered, main='Variance of Temperature')
```
##### Even after differencing the series, it is evident from the above plot that the variance for temperature does not look stationary.

### Method 3

##### I am planning to try to fit a regression+cyclic function to the residuals to test stationarity for both the variables - Demand and Temperature.

##### First, I am plotting the spectral periodogram to find the frequencies.

```{r}
# finding the frequency from the spectral periodogram for demand
demandRper = spec.pgram(demand_residual,spans=c(25,25),taper=0,log="no")
```
##### We can see that 'Demand' follows systematic cycles. We have spikes at f1 = .142871 and f2 = .2857143 signifying some periodicity every 7 days and 3.5 days respectively.

```{r}
# finding the frequency from the spectral periodogram for temperature
tempRper = spec.pgram(temperature_residual,spans=c(25,25),taper=0,log="no")
```
##### We can see that 'Temperature' follows systematic cycles too. We have a small spike at f3 = .1706667 signifying some periodicity every 6 days.

##### Second, upon finding the frequencies for both the variables, I am creating cyclic functions.

```{r}
f1 = .1428571
f2 = .2857143

time = 1:N

cos1 = cos(2*pi*time*f1)
sin1 = sin(2*pi*time*f1)
cos2 = cos(2*pi*time*f2)
sin2 = sin(2*pi*time*f2)

f3 = .1706667
cos3 = cos(2*pi*time*f3)
sin3 = sin(2*pi*time*f3)
```

##### Third, now I am re-doing the process to test stationarity for both the variables. 

```{r}
# trying regression+cyclic for demand to check for stationarity
res_demand_new = lm(demand~poly(time,6)+cos1+sin1+cos2+sin2)
summary(res_demand_new)
demandR_new = residuals(res_demand_new)
plot(demandR_new, main='residuals of demand')

plot(filter(demandR_new^2, rep(1/10,10), sides = 1), main = 'variance of demand')
demandR_new_per = spec.pgram(demandR_new,spans=c(50,50),taper=0,log="no")
```
##### The variance for demand looks somewhat stationary in the middle but not at the ends. Hence, we can still call it non-stationary, however it has improved compared to the previous one. Moreover, there could be a case where data points at either ends may be outliers, or simply points with high variance.

```{r}
# trying regression+cyclic for temperature to check for stationarity
res_temp_new = lm(temperature~poly(time,4)+cos3+sin3)
summary(res_temp_new)
tempR_new = residuals(res_temp_new)
plot(tempR_new, main='residuals of temperature')

plot(filter(tempR_new^2, rep(1/10,10), sides = 1), main = 'variance of temperature')
tempR_new_per = spec.pgram(tempR_new,spans=c(50,50),taper=0,log="no")
```
##### The variance for temperature looks somewhat stationary in the middle but not at the ends, especially the right end. Hence, we can still call it non-stationary, however it has improved compared to the previous one. Moreover, there could be a case where the data points at either ends may be outliers, or simply points with high variance.

## Question 5

```{r}
# checking for lag=50
cat("Autocorrelation for Demand")
acf(demandR_new, 50, main = 'ACF for Demand') 
cat("Autocorrelation for Temperature")
acf(tempR_new, 50, main = 'ACF for Temperature')
```
##### For the ACF plot of Demand:
##### The ACF shows a significant spike at lag 0, which is always 1 because a dataset is perfectly correlated with itself at lag 0. The ACF quickly drops off to within the confidence bounds (the blue dashed lines) from lag 3 onwards. This drop-off suggests that there is little to no autocorrelation in the time series at lags greater than 0, indicating that the noise is likely "white noise."

##### For the ACF plot of Temperature:
##### Similar to the first plot, there is a spike at lag 0. The remaining lags are mostly within the confidence bounds, which means they are not statistically significant. This pattern also indicates that the time series may be white noise, as there is no evidence of autocorrelation at any lag.

##### Upon looking at the auto correlation plot for demand, it looks it is an AR process. But we can infer from above that the spectral periodogram of demand is cosine, hence follows MA process. Hence, since it is a combination / mixture of both, we can say that demand is probably an ARMA process.

##### Upon looking at the auto correlation plot for temperature, it is evident that it is a MA process and the same can be proved by looking at the spectral periodogram of temperature, which has a cosine shape.

##### The poitive and negative correlation over different lags indicate that both the variables follow a cyclic systematic trend.

## Question 6

```{r}
cat("Crosscorrelation for residuals of demand and temperature")
ccf(demandR_new, tempR_new, main = 'Cross Correlation', ylab="CCF")

AH = cbind(tempR_new, demandR_new)
H = spectrum(AH,spans=c(20,20),taper=0,log="no",plot=FALSE)
plot(H$freq,H$coh,type="l",xlab="freq")
```
##### From the cross-correlation plot, we can say that both the series are leading each other at lag of 1. Also, from the squared coherence, there seems to be some correlation between the two series at f = .21 and f = .32.

##### The cross-correlation plot is symmetric around lag 0 because the correlations at negative lags are the same as those at positive lags, but in reverse order. The plot shows that for most lags, the correlations are within the confidence bounds (indicated by the blue dashed lines), suggesting that there are no significant correlations at those lags.

##### In the spectral density coherence plot, there are several peaks, suggesting the presence of multiple periodic components in the data.

##### The peak of the cross-correlation function is at a positive lag, it suggests that the demand is anticipating the temperature.


# ----------------- #


# HW 4

## Question 3

```{r}
# finding the frequency from the spectral periodogram for demand
demandRper = spec.pgram(demand_residual,spans=c(25,25),taper=0,log="no")
```

##### We can see that 'Demand' follows systematic cycles. We have spikes at f1 = .142871 and f2 = .2857143 signifying some periodicity every 7 days and 3.5 days respectively.

```{r}
# finding the frequency from the spectral periodogram for demand
temperatureRper = spec.pgram(temperature_residual,spans=c(25,25),taper=0,log="no")
```

##### We can see that 'Temperature' follows systematic cycles too. We have a small spike at f3 = .1706667 signifying some periodicity every 6 days.

```{r}
f1 = .1428571
f2 = .2857143

time = 1:N

cos1 = cos(2*pi*time*f1)
sin1 = sin(2*pi*time*f1)
cos2 = cos(2*pi*time*f2)
sin2 = sin(2*pi*time*f2)

f3 = .1706667
cos3 = cos(2*pi*time*f3)
sin3 = sin(2*pi*time*f3)
```

```{r}
# trying regression+cyclic for demand to remove systematic cycles
res_demand_new = lm(demand~poly(time,6)+cos1+sin1+cos2+sin2)
summary(res_demand_new)
demandR_new = residuals(res_demand_new)
plot(demandR_new, main='residuals of demand')
plot(filter(demandR_new^2, rep(1/10,10), sides = 1), main = 'variance of demand')
```

```{r}
# checking for window size = 20
m = 250
k = kernel("daniell",m)
demandR_new_per = spec.pgram(demandR_new,k,spans=c(20,20),taper=0,log="no")
```

```{r}
# checking for window size = 35
m = 250
k = kernel("daniell",m)
demandR_new_per = spec.pgram(demandR_new,k,spans=c(35,35),taper=0,log="no")
```

```{r}
# checking for window size = 50
m = 250
k = kernel("daniell",m)
demandR_new_per = spec.pgram(demandR_new,k,spans=c(50,50),taper=0,log="no")
```

```{r}
# trying regression+cyclic for temperature to remove systematic cycles
res_temp_new = lm(temperature~poly(time,4)+cos3+sin3)
summary(res_temp_new)
tempR_new = residuals(res_temp_new)
plot(tempR_new, main='residuals of temperature')
plot(filter(tempR_new^2, rep(1/10,10), sides = 1), main = 'variance of temperature')
```

```{r}
# checking for window size = 20
m = 250
k = kernel("daniell",m)
tempR_new_per = spec.pgram(tempR_new,k,spans=c(20,20),taper=0,log="no")
```

```{r}
# checking for window size = 35
m = 250
k = kernel("daniell",m)
tempR_new_per = spec.pgram(tempR_new,k,spans=c(35,35),taper=0,log="no")
```

```{r}
# checking for window size = 50
m = 250
k = kernel("daniell",m)
tempR_new_per = spec.pgram(tempR_new,k,spans=c(50,50),taper=0,log="no")
```


## Question 4 

##### Again, trying different window sizes for finding estimated spectral distribution

```{r}
# trying window size = 20
H = spectrum(demandR_new,k,spans=c(20,20),taper=0,log="no",main="Spectral Distribution for Demand")
```

##### The demand periodogram of window size=20 has several peaks and troughs, suggesting that there are frequencies where the demand data exhibits more or less regularity. Notably, there are peaks at certain frequencies, which could correspond to periodic components or cycles in the demand data. These could be daily or seasonal demand variations, or other cyclical patterns inherent to the dataset. The bandwidth mentioned in the plot (0.0218) is a parameter of the spectral analysis that relates to the smoothing of the spectral estimate.

```{r}
# trying window size = 40
H = spectrum(demandR_new,k,spans=c(40,40),taper=0,log="no",main="Spectral Distribution for Demand")
```

```{r}
# trying window size = 60
H = spectrum(demandR_new,k,spans=c(60,60),taper=0,log="no",main="Spectral Distribution for Demand")
```

##### Since the periodogram for demand does not show sharp peaks and troughs, it indicates there is a presence of dominant periodic components. 

##### The window size of 60 is chosen to balance the trade-off between resolution and variance, providing a middle ground that offers a reasonable compromise. It also relates to the sampling frequency of the data. For instance, if the data were sampled daily, a window size of 60 days might capture about two months' worth of data, which could be significant for analyzing demand effects.

##### Although the spectral density for Demand has a cosine shape, we also saw in the previous assignment that it is an AR process. Therefore, we can say that Demand is an ARMA process.


```{r}
# trying window size = 20
H = spectrum(tempR_new,spans=c(20,20),taper=0,log="no",main="Periodogram for Temperature")
```

##### The temperature periodogram of window size=20 has several peaks and troughs, suggesting that there are frequencies where the temperature data exhibits more or less regularity. Notably, there are peaks at certain frequencies, which could correspond to periodic components or cycles in the temperature data. These could be daily or seasonal variations, or other cyclical patterns inherent to the dataset. The bandwidth mentioned in the plot (0.0218) is a parameter of the spectral analysis that relates to the smoothing of the spectral estimate.

```{r}
# trying window size = 40
H = spectrum(tempR_new,spans=c(40,40),taper=0,log="no",main="Periodogram for Temperature")
```

```{r}
# trying window size = 60
H = spectrum(tempR_new,spans=c(60,60),taper=0,log="no",main="Periodogram for Temperature")
```

##### Since the periodogram does not show sharp peaks and troughs, it indicates there is a presence of dominant periodic components. 

##### The window size of 60 is chosen to balance the trade-off between resolution and variance, providing a middle ground that offers a reasonable compromise. It also relates to the sampling frequency of the data. For instance, if the data were sampled daily, a window size of 60 days might capture about two months' worth of data, which could be significant for analyzing seasonal effects.

##### The spectral density for Temperature has a cosine shape which means it is MA process.


## Question 5

```{r}
ccf(demandR_new, tempR_new, main = 'Cross Correlation', ylab="CCF")

AH = cbind(tempR_new, demandR_new)
H = spectrum(AH,spans=c(20,20),taper=0,log="no",plot=FALSE)
plot(H$freq,H$coh,type="l",xlab="freq",main="Coherence")

H = spectrum(AH,spans=c(60,60),plot.type="coherency",main="Squared Coherence")
```

##### From the cross-correlation plot, we can say that both the series are leading each other at lag of 1. Also, from the squared coherence, there seems to be some correlation between the two series at f = .21 and f = .32. The cross-correlation plot is symmetric around lag 0 because the correlations at negative lags are the same as those at positive lags, but in reverse order. The plot shows that for most lags, the correlations are within the confidence bounds (indicated by the blue dashed lines), suggesting that there are no significant correlations at those lags.

##### In the spectral density coherence plot, there are peaks, suggesting the presence of multiple periodic components in the data. The values in the coherenc plot fluctuate more than in the squared coherence plot and reach higher peaks. This is the typical appearance of a coherence function. There appear to be peaks around 0.05, 0.2, 0.33 and just before 0.5 frequencies, which suggests that there is some degree of correlation between the two signals at these frequencies, although the correlation is not that high.

##### The squared coherence plot shows that the squared coherence fluctuates around a value slightly above 0, indicating a low level of correlation between the signals across the frequency range shown. There are no peaks that rise above the upper confidence bound, which suggests that there is no significant correlation at any frequency within the range of 0 to 0.5.
